{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>SMA</th>\n",
       "      <th>EMA</th>\n",
       "      <th>WMA</th>\n",
       "      <th>DEMA</th>\n",
       "      <th>TEMA</th>\n",
       "      <th>TRIMA</th>\n",
       "      <th>...</th>\n",
       "      <th>STOCHF-FastD</th>\n",
       "      <th>STOCKF-FastK</th>\n",
       "      <th>RSI</th>\n",
       "      <th>STOCHRSI-FastD</th>\n",
       "      <th>STOCHRSI-FastK</th>\n",
       "      <th>WILLR</th>\n",
       "      <th>ADX</th>\n",
       "      <th>ADXR</th>\n",
       "      <th>APO</th>\n",
       "      <th>PPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36304.4297</td>\n",
       "      <td>36389.2188</td>\n",
       "      <td>36082.9688</td>\n",
       "      <td>23300</td>\n",
       "      <td>35600.2137</td>\n",
       "      <td>35626.1063</td>\n",
       "      <td>35688.0792</td>\n",
       "      <td>35939.9651</td>\n",
       "      <td>36045.0672</td>\n",
       "      <td>35488.1156</td>\n",
       "      <td>...</td>\n",
       "      <td>89.8132</td>\n",
       "      <td>86.9458</td>\n",
       "      <td>68.7552</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>-13.0542</td>\n",
       "      <td>18.9468</td>\n",
       "      <td>19.0408</td>\n",
       "      <td>535.9070</td>\n",
       "      <td>1.5310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35997.2891</td>\n",
       "      <td>36253.8516</td>\n",
       "      <td>35946.2383</td>\n",
       "      <td>40500</td>\n",
       "      <td>35484.3457</td>\n",
       "      <td>35475.3678</td>\n",
       "      <td>35538.9730</td>\n",
       "      <td>35708.2344</td>\n",
       "      <td>35755.7004</td>\n",
       "      <td>35453.6277</td>\n",
       "      <td>...</td>\n",
       "      <td>85.4471</td>\n",
       "      <td>93.8546</td>\n",
       "      <td>64.6462</td>\n",
       "      <td>80.2607</td>\n",
       "      <td>100.000</td>\n",
       "      <td>-6.1454</td>\n",
       "      <td>16.8818</td>\n",
       "      <td>18.0749</td>\n",
       "      <td>505.4852</td>\n",
       "      <td>1.4478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35635.5195</td>\n",
       "      <td>35822.1602</td>\n",
       "      <td>35605.3398</td>\n",
       "      <td>27500</td>\n",
       "      <td>35417.6309</td>\n",
       "      <td>35359.3853</td>\n",
       "      <td>35433.5806</td>\n",
       "      <td>35528.0176</td>\n",
       "      <td>35521.7972</td>\n",
       "      <td>35447.7939</td>\n",
       "      <td>...</td>\n",
       "      <td>70.7071</td>\n",
       "      <td>88.6392</td>\n",
       "      <td>58.9192</td>\n",
       "      <td>46.9273</td>\n",
       "      <td>100.000</td>\n",
       "      <td>-11.3608</td>\n",
       "      <td>15.0797</td>\n",
       "      <td>17.6229</td>\n",
       "      <td>496.6389</td>\n",
       "      <td>1.4246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35394.7695</td>\n",
       "      <td>35555.1602</td>\n",
       "      <td>35262.9688</td>\n",
       "      <td>19100</td>\n",
       "      <td>35338.6980</td>\n",
       "      <td>35298.0221</td>\n",
       "      <td>35379.6131</td>\n",
       "      <td>35442.7651</td>\n",
       "      <td>35411.2731</td>\n",
       "      <td>35429.2964</td>\n",
       "      <td>...</td>\n",
       "      <td>42.7894</td>\n",
       "      <td>73.8474</td>\n",
       "      <td>54.5052</td>\n",
       "      <td>13.5940</td>\n",
       "      <td>40.782</td>\n",
       "      <td>-26.6597</td>\n",
       "      <td>14.9778</td>\n",
       "      <td>18.2013</td>\n",
       "      <td>506.4294</td>\n",
       "      <td>1.4544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35118.0898</td>\n",
       "      <td>35397.2383</td>\n",
       "      <td>34896.0703</td>\n",
       "      <td>19200</td>\n",
       "      <td>35327.9699</td>\n",
       "      <td>35276.5227</td>\n",
       "      <td>35367.4677</td>\n",
       "      <td>35431.9313</td>\n",
       "      <td>35404.1068</td>\n",
       "      <td>35395.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>22.2940</td>\n",
       "      <td>49.6347</td>\n",
       "      <td>48.8170</td>\n",
       "      <td>12.1071</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-40.5319</td>\n",
       "      <td>16.4131</td>\n",
       "      <td>20.0469</td>\n",
       "      <td>492.9727</td>\n",
       "      <td>1.4155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         open        high         low  volume         SMA         EMA  \\\n",
       "0  36304.4297  36389.2188  36082.9688   23300  35600.2137  35626.1063   \n",
       "1  35997.2891  36253.8516  35946.2383   40500  35484.3457  35475.3678   \n",
       "2  35635.5195  35822.1602  35605.3398   27500  35417.6309  35359.3853   \n",
       "3  35394.7695  35555.1602  35262.9688   19100  35338.6980  35298.0221   \n",
       "4  35118.0898  35397.2383  34896.0703   19200  35327.9699  35276.5227   \n",
       "\n",
       "          WMA        DEMA        TEMA       TRIMA   ...    STOCHF-FastD  \\\n",
       "0  35688.0792  35939.9651  36045.0672  35488.1156   ...         89.8132   \n",
       "1  35538.9730  35708.2344  35755.7004  35453.6277   ...         85.4471   \n",
       "2  35433.5806  35528.0176  35521.7972  35447.7939   ...         70.7071   \n",
       "3  35379.6131  35442.7651  35411.2731  35429.2964   ...         42.7894   \n",
       "4  35367.4677  35431.9313  35404.1068  35395.6194   ...         22.2940   \n",
       "\n",
       "   STOCKF-FastK      RSI  STOCHRSI-FastD  STOCHRSI-FastK    WILLR      ADX  \\\n",
       "0       86.9458  68.7552        100.0000         100.000 -13.0542  18.9468   \n",
       "1       93.8546  64.6462         80.2607         100.000  -6.1454  16.8818   \n",
       "2       88.6392  58.9192         46.9273         100.000 -11.3608  15.0797   \n",
       "3       73.8474  54.5052         13.5940          40.782 -26.6597  14.9778   \n",
       "4       49.6347  48.8170         12.1071           0.000 -40.5319  16.4131   \n",
       "\n",
       "      ADXR       APO     PPO  \n",
       "0  19.0408  535.9070  1.5310  \n",
       "1  18.0749  505.4852  1.4478  \n",
       "2  17.6229  496.6389  1.4246  \n",
       "3  18.2013  506.4294  1.4544  \n",
       "4  20.0469  492.9727  1.4155  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs=[ 'open', 'high', 'low',  \n",
    "        'volume', 'SMA', 'EMA','WMA', 'DEMA', 'TEMA', 'TRIMA', 'KAMA', \n",
    "        'MAMA-FAMA', 'MAMA-MAMA', 'T3','MACD-MACD', 'MACD-MACD_Hist',\n",
    "        'MACD-MACD_Signal', 'MACDEXT-MACD','MACDEXT-MACD_Hist', 'MACDEXT-MACD_Signal',\n",
    "        'SlowD', 'SlowK','STOCHF-FastD', 'STOCKF-FastK', 'RSI', 'STOCHRSI-FastD',\n",
    "       'STOCHRSI-FastK', 'WILLR', 'ADX', 'ADXR', 'APO', 'PPO']\n",
    "dataset=pd.read_csv(\"../Datasets/BSE.csv\",usecols=cs)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.iloc[:,:].values\n",
    "Y= pd.read_csv(\"../Datasets/BSE.csv\",\n",
    "               usecols=['close']).iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "X= mms.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test= train_test_split(X,Y,test_size= 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor= LinearRegression()\n",
    "regressor.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998894801428204"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.931130</td>\n",
       "      <td>0.933305</td>\n",
       "      <td>0.930919</td>\n",
       "      <td>0.058032</td>\n",
       "      <td>0.901365</td>\n",
       "      <td>0.905070</td>\n",
       "      <td>0.903654</td>\n",
       "      <td>0.909742</td>\n",
       "      <td>0.915375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.896234</td>\n",
       "      <td>0.869458</td>\n",
       "      <td>0.771357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.869458</td>\n",
       "      <td>0.265128</td>\n",
       "      <td>0.273158</td>\n",
       "      <td>0.579374</td>\n",
       "      <td>0.563311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.923252</td>\n",
       "      <td>0.929833</td>\n",
       "      <td>0.927392</td>\n",
       "      <td>0.100872</td>\n",
       "      <td>0.897593</td>\n",
       "      <td>0.900230</td>\n",
       "      <td>0.898915</td>\n",
       "      <td>0.902752</td>\n",
       "      <td>0.906912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851192</td>\n",
       "      <td>0.938546</td>\n",
       "      <td>0.723519</td>\n",
       "      <td>0.802607</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.938546</td>\n",
       "      <td>0.228469</td>\n",
       "      <td>0.254491</td>\n",
       "      <td>0.575622</td>\n",
       "      <td>0.560766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.913974</td>\n",
       "      <td>0.918761</td>\n",
       "      <td>0.918597</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.895421</td>\n",
       "      <td>0.896507</td>\n",
       "      <td>0.895565</td>\n",
       "      <td>0.897315</td>\n",
       "      <td>0.900072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699131</td>\n",
       "      <td>0.886392</td>\n",
       "      <td>0.656844</td>\n",
       "      <td>0.469273</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.886392</td>\n",
       "      <td>0.196477</td>\n",
       "      <td>0.245755</td>\n",
       "      <td>0.574531</td>\n",
       "      <td>0.560056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.907799</td>\n",
       "      <td>0.911913</td>\n",
       "      <td>0.909764</td>\n",
       "      <td>0.047572</td>\n",
       "      <td>0.892851</td>\n",
       "      <td>0.894537</td>\n",
       "      <td>0.893850</td>\n",
       "      <td>0.894744</td>\n",
       "      <td>0.896840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411127</td>\n",
       "      <td>0.738474</td>\n",
       "      <td>0.605456</td>\n",
       "      <td>0.135940</td>\n",
       "      <td>0.40782</td>\n",
       "      <td>0.733403</td>\n",
       "      <td>0.194668</td>\n",
       "      <td>0.256933</td>\n",
       "      <td>0.575738</td>\n",
       "      <td>0.560968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900703</td>\n",
       "      <td>0.907862</td>\n",
       "      <td>0.900298</td>\n",
       "      <td>0.047821</td>\n",
       "      <td>0.892502</td>\n",
       "      <td>0.893846</td>\n",
       "      <td>0.893464</td>\n",
       "      <td>0.894417</td>\n",
       "      <td>0.896630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199693</td>\n",
       "      <td>0.496347</td>\n",
       "      <td>0.539232</td>\n",
       "      <td>0.121071</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.594681</td>\n",
       "      <td>0.220148</td>\n",
       "      <td>0.292603</td>\n",
       "      <td>0.574078</td>\n",
       "      <td>0.559778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4         5         6         7   \\\n",
       "0  1.0  0.931130  0.933305  0.930919  0.058032  0.901365  0.905070  0.903654   \n",
       "1  1.0  0.923252  0.929833  0.927392  0.100872  0.897593  0.900230  0.898915   \n",
       "2  1.0  0.913974  0.918761  0.918597  0.068493  0.895421  0.896507  0.895565   \n",
       "3  1.0  0.907799  0.911913  0.909764  0.047572  0.892851  0.894537  0.893850   \n",
       "4  1.0  0.900703  0.907862  0.900298  0.047821  0.892502  0.893846  0.893464   \n",
       "\n",
       "         8         9     ...           23        24        25        26  \\\n",
       "0  0.909742  0.915375    ...     0.896234  0.869458  0.771357  1.000000   \n",
       "1  0.902752  0.906912    ...     0.851192  0.938546  0.723519  0.802607   \n",
       "2  0.897315  0.900072    ...     0.699131  0.886392  0.656844  0.469273   \n",
       "3  0.894744  0.896840    ...     0.411127  0.738474  0.605456  0.135940   \n",
       "4  0.894417  0.896630    ...     0.199693  0.496347  0.539232  0.121071   \n",
       "\n",
       "        27        28        29        30        31        32  \n",
       "0  1.00000  0.869458  0.265128  0.273158  0.579374  0.563311  \n",
       "1  1.00000  0.938546  0.228469  0.254491  0.575622  0.560766  \n",
       "2  1.00000  0.886392  0.196477  0.245755  0.574531  0.560056  \n",
       "3  0.40782  0.733403  0.194668  0.256933  0.575738  0.560968  \n",
       "4  0.00000  0.594681  0.220148  0.292603  0.574078  0.559778  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Backward Elimination \n",
    "import statsmodels.formula.api as sm\n",
    "X=np.append(arr=np.ones((2695,1)).astype(int), values=X, axis=1)\n",
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.123e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 24 Jan 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:39:42</td>     <th>  Log-Likelihood:    </th> <td> -15043.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2695</td>      <th>  AIC:               </th> <td>3.015e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2665</td>      <th>  BIC:               </th> <td>3.032e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    29</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.478e+05</td> <td> 5.63e+07</td> <td>    0.008</td> <td> 0.994</td> <td> -1.1e+08</td> <td> 1.11e+08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-1.075e+04</td> <td>  607.326</td> <td>  -17.693</td> <td> 0.000</td> <td>-1.19e+04</td> <td>-9554.625</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td> 2.566e+04</td> <td>  516.552</td> <td>   49.679</td> <td> 0.000</td> <td> 2.46e+04</td> <td> 2.67e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> 2.369e+04</td> <td>  398.139</td> <td>   59.499</td> <td> 0.000</td> <td> 2.29e+04</td> <td> 2.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    7.7618</td> <td>   28.896</td> <td>    0.269</td> <td> 0.788</td> <td>  -48.900</td> <td>   64.423</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td> -257.9358</td> <td>  411.450</td> <td>   -0.627</td> <td> 0.531</td> <td>-1064.729</td> <td>  548.857</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>-4.832e+05</td> <td> 1.92e+05</td> <td>   -2.518</td> <td> 0.012</td> <td>-8.59e+05</td> <td>-1.07e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td> 9238.3790</td> <td> 3215.173</td> <td>    2.873</td> <td> 0.004</td> <td> 2933.892</td> <td> 1.55e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td> 5.224e+05</td> <td> 2.11e+05</td> <td>    2.470</td> <td> 0.014</td> <td> 1.08e+05</td> <td> 9.37e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>-2.309e+04</td> <td> 1.07e+04</td> <td>   -2.159</td> <td> 0.031</td> <td>-4.41e+04</td> <td>-2122.907</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>-3103.5347</td> <td>  902.644</td> <td>   -3.438</td> <td> 0.001</td> <td>-4873.487</td> <td>-1333.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>  124.9844</td> <td>   27.894</td> <td>    4.481</td> <td> 0.000</td> <td>   70.289</td> <td>  179.680</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>  -16.6056</td> <td>   34.884</td> <td>   -0.476</td> <td> 0.634</td> <td>  -85.007</td> <td>   51.796</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   81.7401</td> <td>  100.662</td> <td>    0.812</td> <td> 0.417</td> <td> -115.644</td> <td>  279.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td> 7540.1445</td> <td> 3195.644</td> <td>    2.360</td> <td> 0.018</td> <td> 1273.952</td> <td> 1.38e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>-6.088e+07</td> <td> 1.37e+08</td> <td>   -0.445</td> <td> 0.656</td> <td>-3.29e+08</td> <td> 2.07e+08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>  4.53e+07</td> <td> 1.02e+08</td> <td>    0.444</td> <td> 0.657</td> <td>-1.55e+08</td> <td> 2.45e+08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td> 3.931e+07</td> <td> 8.83e+07</td> <td>    0.445</td> <td> 0.656</td> <td>-1.34e+08</td> <td> 2.13e+08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td> 2.745e+07</td> <td> 1.01e+08</td> <td>    0.273</td> <td> 0.785</td> <td> -1.7e+08</td> <td> 2.25e+08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>  -4.6e+07</td> <td> 1.69e+08</td> <td>   -0.273</td> <td> 0.785</td> <td>-3.77e+08</td> <td> 2.85e+08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>-5.029e+07</td> <td> 1.85e+08</td> <td>   -0.273</td> <td> 0.785</td> <td>-4.12e+08</td> <td> 3.12e+08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>  -13.3896</td> <td>   19.716</td> <td>   -0.679</td> <td> 0.497</td> <td>  -52.051</td> <td>   25.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>  -47.6173</td> <td>   11.098</td> <td>   -4.291</td> <td> 0.000</td> <td>  -69.379</td> <td>  -25.855</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>  -47.6848</td> <td>   11.098</td> <td>   -4.297</td> <td> 0.000</td> <td>  -69.446</td> <td>  -25.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>  267.1892</td> <td>   12.732</td> <td>   20.986</td> <td> 0.000</td> <td>  242.223</td> <td>  292.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td> -173.4916</td> <td>   18.191</td> <td>   -9.537</td> <td> 0.000</td> <td> -209.162</td> <td> -137.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>   20.5220</td> <td>   10.975</td> <td>    1.870</td> <td> 0.062</td> <td>   -0.998</td> <td>   42.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td> -103.5996</td> <td>    6.627</td> <td>  -15.633</td> <td> 0.000</td> <td> -116.594</td> <td>  -90.605</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>   67.9881</td> <td>   11.844</td> <td>    5.741</td> <td> 0.000</td> <td>   44.765</td> <td>   91.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>   27.9238</td> <td>   16.368</td> <td>    1.706</td> <td> 0.088</td> <td>   -4.172</td> <td>   60.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>  -31.0243</td> <td>   16.275</td> <td>   -1.906</td> <td> 0.057</td> <td>  -62.938</td> <td>    0.889</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td> 2.745e+07</td> <td> 1.01e+08</td> <td>    0.273</td> <td> 0.785</td> <td> -1.7e+08</td> <td> 2.25e+08</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>462.277</td> <th>  Durbin-Watson:     </th> <td>   2.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>7212.824</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.313</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>10.990</td>  <th>  Cond. No.          </th> <td>1.08e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 2.21e-28. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 1.123e+06\n",
       "Date:                Thu, 24 Jan 2019   Prob (F-statistic):               0.00\n",
       "Time:                        11:39:42   Log-Likelihood:                -15043.\n",
       "No. Observations:                2695   AIC:                         3.015e+04\n",
       "Df Residuals:                    2665   BIC:                         3.032e+04\n",
       "Df Model:                          29                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.478e+05   5.63e+07      0.008      0.994    -1.1e+08    1.11e+08\n",
       "x1         -1.075e+04    607.326    -17.693      0.000   -1.19e+04   -9554.625\n",
       "x2          2.566e+04    516.552     49.679      0.000    2.46e+04    2.67e+04\n",
       "x3          2.369e+04    398.139     59.499      0.000    2.29e+04    2.45e+04\n",
       "x4             7.7618     28.896      0.269      0.788     -48.900      64.423\n",
       "x5          -257.9358    411.450     -0.627      0.531   -1064.729     548.857\n",
       "x6         -4.832e+05   1.92e+05     -2.518      0.012   -8.59e+05   -1.07e+05\n",
       "x7          9238.3790   3215.173      2.873      0.004    2933.892    1.55e+04\n",
       "x8          5.224e+05   2.11e+05      2.470      0.014    1.08e+05    9.37e+05\n",
       "x9         -2.309e+04   1.07e+04     -2.159      0.031   -4.41e+04   -2122.907\n",
       "x10        -3103.5347    902.644     -3.438      0.001   -4873.487   -1333.582\n",
       "x11          124.9844     27.894      4.481      0.000      70.289     179.680\n",
       "x12          -16.6056     34.884     -0.476      0.634     -85.007      51.796\n",
       "x13           81.7401    100.662      0.812      0.417    -115.644     279.124\n",
       "x14         7540.1445   3195.644      2.360      0.018    1273.952    1.38e+04\n",
       "x15        -6.088e+07   1.37e+08     -0.445      0.656   -3.29e+08    2.07e+08\n",
       "x16          4.53e+07   1.02e+08      0.444      0.657   -1.55e+08    2.45e+08\n",
       "x17         3.931e+07   8.83e+07      0.445      0.656   -1.34e+08    2.13e+08\n",
       "x18         2.745e+07   1.01e+08      0.273      0.785    -1.7e+08    2.25e+08\n",
       "x19          -4.6e+07   1.69e+08     -0.273      0.785   -3.77e+08    2.85e+08\n",
       "x20        -5.029e+07   1.85e+08     -0.273      0.785   -4.12e+08    3.12e+08\n",
       "x21          -13.3896     19.716     -0.679      0.497     -52.051      25.271\n",
       "x22          -47.6173     11.098     -4.291      0.000     -69.379     -25.855\n",
       "x23          -47.6848     11.098     -4.297      0.000     -69.446     -25.923\n",
       "x24          267.1892     12.732     20.986      0.000     242.223     292.155\n",
       "x25         -173.4916     18.191     -9.537      0.000    -209.162    -137.821\n",
       "x26           20.5220     10.975      1.870      0.062      -0.998      42.042\n",
       "x27         -103.5996      6.627    -15.633      0.000    -116.594     -90.605\n",
       "x28           67.9881     11.844      5.741      0.000      44.765      91.212\n",
       "x29           27.9238     16.368      1.706      0.088      -4.172      60.019\n",
       "x30          -31.0243     16.275     -1.906      0.057     -62.938       0.889\n",
       "x31         2.745e+07   1.01e+08      0.273      0.785    -1.7e+08    2.25e+08\n",
       "==============================================================================\n",
       "Omnibus:                      462.277   Durbin-Watson:                   2.203\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7212.824\n",
       "Skew:                           0.313   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.990   Cond. No.                     1.08e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 2.21e-28. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt= X[:,range(0,len(cs))]\n",
    "SL= 0.05\n",
    "regressor_ols= sm.OLS(endog= Y, exog= X_opt).fit()\n",
    "regressor_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   1.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>3.854e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 24 Jan 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:40:21</td>     <th>  Log-Likelihood:    </th> <td> -15128.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2695</td>      <th>  AIC:               </th> <td>3.027e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2686</td>      <th>  BIC:               </th> <td>3.033e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  -12.3698</td> <td>    6.657</td> <td>   -1.858</td> <td> 0.063</td> <td>  -25.423</td> <td>    0.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-1.237e+04</td> <td>  597.199</td> <td>  -20.721</td> <td> 0.000</td> <td>-1.35e+04</td> <td>-1.12e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td> 2.719e+04</td> <td>  503.390</td> <td>   54.023</td> <td> 0.000</td> <td> 2.62e+04</td> <td> 2.82e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> 2.379e+04</td> <td>  388.967</td> <td>   61.168</td> <td> 0.000</td> <td>  2.3e+04</td> <td> 2.46e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>  176.0411</td> <td>   23.230</td> <td>    7.578</td> <td> 0.000</td> <td>  130.490</td> <td>  221.592</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>  -64.4959</td> <td>    6.744</td> <td>   -9.563</td> <td> 0.000</td> <td>  -77.720</td> <td>  -51.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>  -64.4959</td> <td>    6.744</td> <td>   -9.563</td> <td> 0.000</td> <td>  -77.720</td> <td>  -51.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>  299.2659</td> <td>    9.650</td> <td>   31.012</td> <td> 0.000</td> <td>  280.344</td> <td>  318.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   37.4451</td> <td>    9.316</td> <td>    4.020</td> <td> 0.000</td> <td>   19.178</td> <td>   55.712</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td> -113.2343</td> <td>    5.635</td> <td>  -20.095</td> <td> 0.000</td> <td> -124.283</td> <td> -102.185</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>438.374</td> <th>  Durbin-Watson:     </th> <td>   2.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>6960.759</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.226</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>10.860</td>  <th>  Cond. No.          </th> <td>2.15e+17</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 2.25e-31. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       1.000\n",
       "Model:                            OLS   Adj. R-squared:                  1.000\n",
       "Method:                 Least Squares   F-statistic:                 3.854e+06\n",
       "Date:                Thu, 24 Jan 2019   Prob (F-statistic):               0.00\n",
       "Time:                        11:40:21   Log-Likelihood:                -15128.\n",
       "No. Observations:                2695   AIC:                         3.027e+04\n",
       "Df Residuals:                    2686   BIC:                         3.033e+04\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        -12.3698      6.657     -1.858      0.063     -25.423       0.683\n",
       "x1         -1.237e+04    597.199    -20.721      0.000   -1.35e+04   -1.12e+04\n",
       "x2          2.719e+04    503.390     54.023      0.000    2.62e+04    2.82e+04\n",
       "x3          2.379e+04    388.967     61.168      0.000     2.3e+04    2.46e+04\n",
       "x4           176.0411     23.230      7.578      0.000     130.490     221.592\n",
       "x5           -64.4959      6.744     -9.563      0.000     -77.720     -51.272\n",
       "x6           -64.4959      6.744     -9.563      0.000     -77.720     -51.272\n",
       "x7           299.2659      9.650     31.012      0.000     280.344     318.188\n",
       "x8            37.4451      9.316      4.020      0.000      19.178      55.712\n",
       "x9          -113.2343      5.635    -20.095      0.000    -124.283    -102.185\n",
       "==============================================================================\n",
       "Omnibus:                      438.374   Durbin-Watson:                   2.193\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6960.759\n",
       "Skew:                           0.226   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.860   Cond. No.                     2.15e+17\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 2.25e-31. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt= X[:,[0,1,2,3,14,22,23,24,26,27]]\n",
    "SL= 0.05\n",
    "regressor_ols= sm.OLS(endog= Y, exog= X_opt).fit()\n",
    "regressor_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2695, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2695, 2156]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2d3bc05ff3b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mregressor2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mregressor2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 482\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2695, 2156]"
     ]
    }
   ],
   "source": [
    "cs=[ 'open', 'high', 'low',  \n",
    "        'volume', 'SMA', 'EMA','WMA', 'DEMA', 'TEMA', 'TRIMA', 'KAMA', \n",
    "        'MAMA-FAMA', 'MAMA-MAMA', 'T3','MACD-MACD', 'MACD-MACD_Hist',\n",
    "        'MACD-MACD_Signal', 'MACDEXT-MACD','MACDEXT-MACD_Hist', 'MACDEXT-MACD_Signal',\n",
    "        'SlowD', 'SlowK','STOCHF-FastD', 'STOCKF-FastK', 'RSI', 'STOCHRSI-FastD',\n",
    "       'STOCHRSI-FastK', 'WILLR', 'ADX', 'ADXR', 'APO', 'PPO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
